{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pUfPDjk_LAN"
      },
      "source": [
        "# هفته سوم - درس ۳: یادداشت منتقدان غذا\n",
        "\n",
        "از هوش مصنوعی کمک می‌گیری که بفهمی آیا محتوای فایل پیرامون غذا و رستوران‌ها هست یا نه.\n",
        "\n",
        "داده‌های متنی مانند ایمیل‌ها، نوشته‌های شبکه اجتماعی و نقدهای روزنامه ساختار یکسان و منظمی ندارند.\n",
        "نوشته یک نفر پر از بولت‌هاست و دیگری بندهای طولانی.\n",
        "\n",
        "به همین دلیل به داده‌های متنی داده‌های «بی‌ساختار» می‌گویند.\n",
        "\n",
        "`unstructured data`"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## کلون مخزن گیت‌هاب برای کار با فایل‌های درس"
      ],
      "metadata": {
        "id": "HCmc3qdt5ns1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists('Python-with-AI'):\n",
        "    !git clone https://github.com/asefycom/Python-with-AI.git\n",
        "\n",
        "os.chdir('Python-with-AI/3rd-week/L03')\n",
        "print(\"Current Working Directory:\", os.getcwd())"
      ],
      "metadata": {
        "id": "5rjn6jx35rg7",
        "outputId": "1639e2dc-ece6-4e48-d7a5-3475c5cc05dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Working Directory: /content/Python-with-AI/3rd-week/L03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tYmgYvV_LAQ"
      },
      "source": [
        "## راه‌اندازی توگدر برای کار با هوش مصنوعی\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Tvyi0PuH_LAQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "671abe42-16af-4798-f979-e2c6d3767803",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: together in /usr/local/lib/python3.11/dist-packages (1.5.21)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.3 in /usr/local/lib/python3.11/dist-packages (from together) (3.12.14)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from together) (8.1.8)\n",
            "Requirement already satisfied: eval-type-backport<0.3.0,>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from together) (0.2.2)\n",
            "Requirement already satisfied: filelock<4.0.0,>=3.13.1 in /usr/local/lib/python3.11/dist-packages (from together) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from together) (2.0.2)\n",
            "Requirement already satisfied: pillow<12.0.0,>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from together) (11.3.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.6.3 in /usr/local/lib/python3.11/dist-packages (from together) (2.11.7)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from together) (2.32.3)\n",
            "Requirement already satisfied: rich<15.0.0,>=13.8.1 in /usr/local/lib/python3.11/dist-packages (from together) (13.9.4)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from together) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.2 in /usr/local/lib/python3.11/dist-packages (from together) (4.67.1)\n",
            "Requirement already satisfied: typer<0.16,>=0.9 in /usr/local/lib/python3.11/dist-packages (from together) (0.15.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.20.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (4.14.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->together) (2025.7.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<15.0.0,>=13.8.1->together) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<15.0.0,>=13.8.1->together) (2.19.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<0.16,>=0.9->together) (1.5.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=13.8.1->together) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install together"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from together import Together\n",
        "\n",
        "client = Together(api_key=userdata.get('TOGETHER_API_KEY'))\n",
        "\n",
        "def print_llm_response(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"google/gemma-3n-E4B-it\",\n",
        "        # model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\",\n",
        "        messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt\n",
        "        }\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "q6tiBEpvB9kP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjt2Edlq_LAR"
      },
      "source": [
        "## کار با فایل متنی"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R11PZCmZ_LAS"
      },
      "source": [
        "بیا با هم نگاهی به یادداشت‌ها و خاطرات سفر منتشر شده توسط دیگران بندازیم.\n",
        "\n",
        "\n",
        "\n",
        "> برای به دست اوردن چنین فایل‌هایی نمیشه از چت‌بات و جستجوی آنلاینش کمک گرفت؟ یا شاید از [ایجنت زپیر](https://hamruyesh.com/product/social-content-automation-by-ai-agent-tutorial/) بخواهی که جستجو و یافته ها رو به صورت فایل متنی داخل گوگل درایو ذخیره کنه.\n",
        "\n",
        "\n",
        "\n",
        "بگذریم. حالا بیا روی همین فایل‌های آماده تمرکز کنیم.\n",
        "\n",
        " یادداشت‌ها به فرمت تکست هستن و برای شروع بیا فایل تکست کیپ تاون رو باز کنیم که هم مسیر با همین دفترچه برات ذخیره کردم.\n",
        "\n",
        "دقت کن که چون هم مسیر هستن فقط نام فایل رو دادم و کافی هست."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kNFexh5y_LAS"
      },
      "outputs": [],
      "source": [
        "f = open(\"cape_town.txt\", \"r\")\n",
        "journal_cape_town = f.read()\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9mDLp_C_LAS"
      },
      "source": [
        "محتوای متنی این یادداشت رو چاپ کنیم:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JMApHfP6_LAS",
        "outputId": "74361d92-7ec2-43ac-aaeb-315f26a388ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My first destination was The Test Kitchen, a restaurant that has earned its place among the world's best. Situated in the trendy Woodstock area, this dining spot is celebrated for its innovative dishes. I was particularly taken by their signature dish, the \"Pickled Fish Tacos.\" The tangy, flavorful fish wrapped in a soft taco, paired with a zesty salsa, was a delightful start to my culinary adventure. The industrial-chic ambiance added a modern edge to the dining experience.\n",
            "\n",
            "Next, I made my way to La Colombe, perched on the slopes of Constantia. Known for its refined and artistic approach to cuisine, La Colombe's \"Tuna La Colombe\" is a must-try. This dish features perfectly seared tuna, complemented by a delicate ponzu dressing and bursts of citrus. The presentation was as exquisite as the flavors, making it a memorable highlight of the day.\n",
            "\n",
            "At the bustling V&A Waterfront, I visited Harbour House for some of the freshest seafood in town. The \"Grilled Kingklip\" was a revelation. The succulent, flaky fish, grilled to perfection and served with a side of roasted vegetables, highlighted the ocean's bounty. The stunning views of the harbor added to the meal's appeal.\n",
            "\n",
            "Finally, my journey concluded at The Pot Luck Club, another gem in Woodstock. This trendy spot is known for its small plates, perfect for sharing. The standout dish was the \"Beef Tataki.\" Thinly sliced, seared beef with a tangy soy dressing and a hint of wasabi provided a burst of umami and heat. The eclectic, artistic vibe of the restaurant made for a fitting end to my culinary tour.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(journal_cape_town)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yUeYbJw_LAT"
      },
      "source": [
        "این یادداشت در مورد غذاها و رستوران‌هاست درست؟\n",
        "\n",
        "به همین ترتیب نگاهی بنداز به یادداشت‌های توکیو"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kZNPersn_LAU"
      },
      "outputs": [],
      "source": [
        "f = open(\"tokyo.txt\", \"r\")\n",
        "journal_tokyo = f.read()\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkGFOPuJ_LAV"
      },
      "source": [
        "بعد از باز کردن فایل حالا محتواش رو چاپ کن:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LeKaPOSy_LAV",
        "outputId": "25830c0e-4814-420c-b2ad-019cc24d735c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokyo's culinary landscape is nothing short of extraordinary. Each spot offers a unique taste of the city's diverse food culture. Here's a quick guide to some must-try places and dishes.\n",
            "\n",
            "    Sukiyabashi Jiro\n",
            "        Location: Ginza\n",
            "        Dish: Omakase sushi\n",
            "        Highlight: Impeccably crafted sushi made by the legendary Jiro Ono. Each piece is a masterclass in balance and flavor.\n",
            "\n",
            "    Ichiran Ramen\n",
            "        Location: Shibuya\n",
            "        Dish: Tonkotsu ramen\n",
            "        Highlight: A personal ramen booth for focused, uninterrupted enjoyment. Rich, creamy broth with perfectly cooked noodles.\n",
            "\n",
            "    Tsukiji Outer Market\n",
            "        Location: Tsukiji\n",
            "        Dish: Fresh sashimi and street food\n",
            "        Highlight: Vibrant market atmosphere. Indulge in ultra-fresh sashimi, grilled seafood, and other Japanese street food delights.\n",
            "\n",
            "    Narisawa\n",
            "        Location: Minato\n",
            "        Dish: Innovative tasting menu\n",
            "        Highlight: A fusion of French and Japanese techniques. Creative dishes with an emphasis on sustainability and local ingredients.\n",
            "\n",
            "    Ginza Kojyu\n",
            "        Location: Ginza\n",
            "        Dish: Kaiseki (traditional multi-course meal)\n",
            "        Highlight: Exquisite presentation and meticulous preparation. A journey through seasonal Japanese flavors.\n",
            "\n",
            "    Akasaka Kikunoi\n",
            "        Location: Akasaka\n",
            "        Dish: Kaiseki\n",
            "        Highlight: Elegant and serene setting. Seasonal ingredients transformed into artful, delicious courses.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(journal_tokyo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5653_Wx7_LAV"
      },
      "source": [
        "این یادداشت هم در مورد رستوران‌ها و غذاهاست نه؟\n",
        "\n",
        " اما دقت کن که چقدر ساختار این نوشته با یادداشت کیپ تاون فرق داشت."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edVbtJCm_LAW"
      },
      "source": [
        "## LLM  تحلیل محتوای فایل‌ با"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YduTIwde_LAW"
      },
      "source": [
        "بیا پرامپتی بنویسیم و به ال‌ال‌ام بفرستیم تا بررسی و اعلام کنه که آیا محتوای یک فایل درباره غذا و رستوران‌ها هست یا نه.\n",
        "\n",
        "این پرامپت با متغیر «یادداشت توکیو» پر شده."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "M4-CkV3N_LAW"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"با عبارت «مرتبط» یا «نامرتبط» به من پاسخ بده:\n",
        "آیا این یادداشت به توصیف رستوران ها و غذاهای آن ها می پردازد؟\n",
        "\n",
        "یادداشت:\n",
        "{journal_tokyo}\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4OoCgwN_LAW"
      },
      "source": [
        "و حالا پاسخ مدل زبانی بزرگ یا به اصطلاح ساده‌انگارانه‌تر، هوش مصنوعی:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1iV9Vm4y_LAX",
        "outputId": "e45c4301-9bdf-49f4-dc54-2fd279c4e329",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "مرتبط\n",
            "\n"
          ]
        }
      ],
      "source": [
        "res = print_llm_response(prompt)\n",
        "print(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljFMTbHa_LAX"
      },
      "source": [
        "## بررسی همه فایل‌ها با حلقه فور"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE4H91ec_LAX"
      },
      "source": [
        "استفاده همزمان از پایتون و هوش مصنوعی اجازه میده که همه فایل‌ها رو در یک حلقه بررسی و ارتباط محتواشون با موضوع غذا رو تعیین کنیم.\n",
        "\n",
        "برای شروع بیا لیست همه یادداشت‌ها (فایل ‌ها) رو ایجاد کنیم."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files = ['istanbul.txt', 'paris.txt', 'rio_de_janeiro.txt', 'sydney.txt', 'tokyo.txt', 'new_york.txt', 'madrid.txt', 'cape_town.txt']"
      ],
      "metadata": {
        "id": "_7_8hm-DDGam"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAb9mGyK_LAX"
      },
      "source": [
        "سپس با یک حلقه فور تک تکاین فایل‌ها رو باز و ارتباط محتواشون با غذا و رستوران‌ها رو بررسی می‌کنیم.\n",
        "\n",
        "* اگه لازم می‌بینی برای یادآوری حلقه فور به محتوای هفته دوم برگرد."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "aJd6jpg0_LAY",
        "outputId": "e67fc6be-10e0-41f8-f849-788f168b5517",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "istanbul.txt -> مرتبط\n",
            "\n",
            "paris.txt -> مرتبط\n",
            "\n",
            "rio_de_janeiro.txt -> مرتبط\n",
            "\n",
            "sydney.txt -> مرتبط\n",
            "\n",
            "tokyo.txt -> مرتبط\n",
            "\n",
            "new_york.txt -> مرتبط\n",
            "\n",
            "madrid.txt -> نامرتبط\n",
            "\n",
            "cape_town.txt -> مرتبط\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for file in files:\n",
        "    # خوندن یادداشت شهر\n",
        "    f = open(file, \"r\")\n",
        "    journal = f.read()\n",
        "    f.close()\n",
        "\n",
        "    # ساخت پرامپت\n",
        "    prompt = f\"\"\"با عبارت «مرتبط» یا «نامرتبط» به من پاسخ بده:\n",
        "    آیا این یادداشت به توصیف رستوران ها و غذای آن ها می پردازد؟\n",
        "\n",
        "    یادداشت:\n",
        "    {journal}\"\"\"\n",
        "\n",
        "    # فرستادن پرامپت به ال‌ال‌ام و چاپ نتیجه\n",
        "    print(f\"{file} -> {print_llm_response(prompt)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"madrid.txt\", \"r\")\n",
        "journal_cape_town = f.read()\n",
        "f.close()"
      ],
      "metadata": {
        "id": "a-J9y-lwoRwx"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zz8hZpwC_LAY",
        "outputId": "0aea418e-9f56-40cb-a15b-0a30554f90ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Madrid, as Spain's capital and largest city, is a key player in the nation's economy. Historically centered around its administrative functions, Madrid has evolved into a major financial hub, hosting the Madrid Stock Exchange and the headquarters of numerous national and international companies.\n",
            "\n",
            "The service sector, especially tourism, is vital to Madrid's economy. Millions of tourists visit annually, attracted by the city's cultural landmarks, museums, and vibrant nightlife. Additionally, trade fairs and conferences at venues like IFEMA (Feria de Madrid) bring significant business traffic.\n",
            "\n",
            "Innovation and technology are also growing sectors in Madrid. The city boasts a thriving startup ecosystem and hosts many tech companies, supported by a highly educated workforce from its universities and research institutions. This has spurred growth in IT, biotechnology, and renewable energy.\n",
            "\n",
            "Madrid's well-developed transportation network, including a comprehensive metro system, high-speed rail, and Adolfo Suárez Madrid-Barajas Airport, enhances its role as a logistical and commercial hub. This connectivity supports trade and commerce, both within Spain and internationally, solidifying Madrid's status as a leading economic center in Europe.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# خوندن و چاپ محتوای یادداشت مادرید\n",
        "f = open(\"madrid.txt\", \"r\")\n",
        "print(f.read())\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GL0H3W9o_LAY"
      },
      "source": [
        "یادداشت مادرید به بررسی رستوران‌های شهر نپرداخته و بیشتر به اقتصاد شهر پرداخته.\n",
        "\n",
        "ببین ما با چند خط کد این همه متن داخل این همه فایل رو یکجا تحلیل کردیم. جالب نیست؟ 💪"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##   تمرین مکمل\n",
        "\n",
        "\n",
        "من یه تکه کد پایتون از چت‌بات گرفتم که نام فایل‌های متنی این دایرکتوری رو به صورت لیست داشته باشم.\n",
        "\n",
        "> Give Python code that returns the names of files with the .txt extension in the current working directory as a list.\n",
        "\n",
        "و این کد رو بهم داد. بررسی و امتحانش کن."
      ],
      "metadata": {
        "id": "O175ocxEDsln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# کدی که دیپ سیک بهم داد\n",
        "import os\n",
        "\n",
        "# دریافت لیست تمام فایل‌ها در دایرکتوری جاری\n",
        "all_files = os.listdir()\n",
        "\n",
        "# فیلتر کردن فایل‌های با پسوند .txt\n",
        "files = [file for file in all_files if file.endswith('.txt')]\n",
        "\n",
        "print(files)"
      ],
      "metadata": {
        "id": "GbC5LwwTD0k3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2067566a-845e-4e2d-ac99-67ef22a5e149"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['rio_de_janeiro.txt', 'tokyo.txt', 'madrid.txt', 'new_york.txt', 'istanbul.txt', 'sydney.txt', 'cape_town.txt', 'paris.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "txt_files = [f for f in os.listdir('.') if f.endswith('.txt') and os.path.isfile(f)]\n",
        "print(txt_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rNaQUSgVF8G",
        "outputId": "7536414c-e87b-4986-edd6-b0689f318b48"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['rio_de_janeiro.txt', 'tokyo.txt', 'madrid.txt', 'new_york.txt', 'istanbul.txt', 'sydney.txt', 'cape_town.txt', 'paris.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def get_txt_files():\n",
        "    \"\"\"Returns a list of .txt files in the current working directory\"\"\"\n",
        "    txt_files = []\n",
        "    for file in os.listdir('.'):\n",
        "        if file.endswith('.txt') and os.path.isfile(file):\n",
        "            txt_files.append(file)\n",
        "    return txt_files\n",
        "\n",
        "# Usage\n",
        "txt_files_list = get_txt_files()\n",
        "print(txt_files_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHLoXluwVK7e",
        "outputId": "2729c2a3-c8f5-4e00-e824-202fe4eaa3df"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['rio_de_janeiro.txt', 'tokyo.txt', 'madrid.txt', 'new_york.txt', 'istanbul.txt', 'sydney.txt', 'cape_town.txt', 'paris.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "txt_files = [f.name for f in Path('.').iterdir() if f.is_file() and f.suffix == '.txt']\n",
        "print(txt_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIERWr9mVN8t",
        "outputId": "712c3532-7e97-4534-d2ef-b6ea224d6797"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['rio_de_janeiro.txt', 'tokyo.txt', 'madrid.txt', 'new_york.txt', 'istanbul.txt', 'sydney.txt', 'cape_town.txt', 'paris.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdLEjqhW_LAY"
      },
      "source": [
        "<p style=\"background-color:#F5C780; padding:15px\"> 🤖 <b>از چت‌بات بپرس</b>:\n",
        "    <br><br>\n",
        "    من دارم از یک مدل‌ زبانی بزرگ استفاده می‌کنم. هر بار متن یک یادداشت رو براش می‌فرستم و اون تعیین می‌کنه که این یادداشت با بحث غذا و رستوران «مرتبط» یا «نامرتبط» هست.     \n",
        "    آیا این کار در هوش مصنوعی نام خاصی داره؟\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "بله، این کار در هوش مصنوعی نام خاصی دارد:\n",
        "\n",
        "**نام تخصصی: Text Classification یا طبقه‌بندی متن**\n",
        "\n",
        "در حوزه پردازش زبان طبیعی (NLP) به این کار می‌گویند:\n",
        "- **Binary Text Classification** (طبقه‌بندی دودویی متن) - چون فقط دو برچسب دارید: \"مرتبط\" و \"نامرتبط\"\n",
        "- **Sentiment Analysis** (تحلیل احساس) - اگر بخواهید تشخیص دهید متن مثبت/منفی درباره غذا است یا نه\n",
        "- **Topic Classification** (طبقه‌بندی موضوعی) - چون دارید متن را بر اساس موضوع (غذا و رستوران) دسته‌بندی می‌کنید\n",
        "\n",
        "**کاربردهای مشابه:**\n",
        "- تشخیص اسپم در ایمیل‌ها\n",
        "- دسته‌بندی اخبار بر اساس موضوع\n",
        "- تشخیص نظرات مثبت/منفی درباره محصولات\n",
        "\n",
        "پس شما در واقع یک سیستم **طبقه‌بندی دودویی متن** برای تشخیص ارتباط یادداشت‌ها با موضوع غذا و رستوران ایجاد کرده‌اید."
      ],
      "metadata": {
        "id": "5D167qpWVaj5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAkx-9cE_LAZ"
      },
      "source": [
        "## تمرین فراتر\n",
        "\n",
        "با یافته‌های این درس و کار با پرامپت‌ها تمرین‌های زیر رو انجام بده.\n",
        "\n",
        "### تمرین ۱\n",
        "\n",
        "این پرامپت رو طوری تغییر بده که متن رو از نظر موضوعش رده‌بندی (کلسیفیکیشن) بکنه. مثلا این که از طراحی رستوران صحبت شده یا نه. یا این که در مورد دسرها صحبت شده یا نه."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files = [\"cape_town.txt\", \"madrid.txt\", \"rio_de_janeiro.txt\",\n",
        "         \"sydney.txt\", \"tokyo.txt\"]\n",
        "\n",
        "for file in files:\n",
        "    # خوندن فایل یادداشت هر شهر\n",
        "    f = open(file, \"r\")\n",
        "    journal = f.read()\n",
        "    f.close()\n",
        "\n",
        "    # این پرامپت رو تغییر بده تا پرسش‌های متفاوتی رو پاسخ بده\n",
        "    prompt = f\"\"\"با بله و نه پاسخ بده:\n",
        "    آیا این یادداشت، غذاها و رستوران‌های رو توصیف می‌کنه؟\n",
        "\n",
        "    یادداشت:\n",
        "    {journal}\"\"\"\n",
        "\n",
        "    # فرستادن پرامپت به ال‌ال‌ام و چاپ پاسخ\n",
        "    print(f\"{file} -> {print_llm_response(prompt)}\")"
      ],
      "metadata": {
        "id": "Xn7Ub3gej9zD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = [\"cape_town.txt\", \"madrid.txt\", \"rio_de_janeiro.txt\",\n",
        "         \"sydney.txt\", \"tokyo.txt\"]\n",
        "\n",
        "questions = {\n",
        "    \"Economy\": \"Does this note mention economy or business?\",\n",
        "    \"Technology\": \"Does this note mention technology or innovation?\",\n",
        "    \"Transportation\": \"Does this note mention transportation, airport, or metro?\",\n",
        "    \"Tourism\": \"Does this note mention tourism or attracting tourists?\"\n",
        "}\n",
        "\n",
        "header = f\"{'City':<15} {'Economy':<10} {'Technology':<12} {'Transportation':<15} {'Tourism':<10}\"\n",
        "print(header)\n",
        "print(\"-\"*65)\n",
        "\n",
        "for file in files:\n",
        "    with open(file, \"r\") as f:\n",
        "        journal = f.read()\n",
        "\n",
        "    results = []\n",
        "    for key, question in questions.items():\n",
        "        prompt = f\"\"\"Answer with Yes or No only:\n",
        "{question}\n",
        "\n",
        "Note:\n",
        "{journal}\"\"\"\n",
        "        response = print_llm_response(prompt)\n",
        "        results.append(response.strip())\n",
        "    city = file.replace(\".txt\", \"\")\n",
        "    print(f\"{city:<15} {results[0]:<10} {results[1]:<12} {results[2]:<15} {results[3]:<10}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uCmjUXKo11p",
        "outputId": "2acc3a2e-c932-4653-908e-9cb57689f603"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "City            Economy    Technology   Transportation  Tourism   \n",
            "-----------------------------------------------------------------\n",
            "cape_town       No         Yes          No              No        \n",
            "madrid          Yes        Yes          Yes             Yes       \n",
            "rio_de_janeiro  No         Yes          No              No        \n",
            "sydney          No         No           No              No        \n",
            "tokyo           No         Yes          No              No        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVEybRJL_LAZ"
      },
      "source": [
        "### تمرین ۲\n",
        "\n",
        "بر بنیان کد پایین و اصلاح پرامپت تلاش کن که یادداشت رو به بیش از ۲ رده یا کلاس تقسیم کنی.\n",
        "\n",
        "**مثال:**\n",
        "- به یک غذای «گیاهی» اشاره می‌کند\n",
        "- به یک غذای «وگان» اشاره می‌کند\n",
        "- به هر دو اشاره شده\n",
        "- به هیچ یک از این دو اشاره نشده"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iles = [\"cape_town.txt\", \"madrid.txt\", \"rio_de_janeiro.txt\",\n",
        "         \"sydney.txt\", \"tokyo.txt\"]\n",
        "\n",
        "for file in files:\n",
        "    # خوندن فایل یادداشت هر شهر\n",
        "    f = open(file, \"r\")\n",
        "    journal = f.read()\n",
        "    f.close()\n",
        "\n",
        "    # تلاش کن این پرامپت رو با توجه به صورت تمرین، تغییر بدی\n",
        "    prompt = f\"\"\"با بله و نه پاسخ بده:\n",
        "    آیا این یادداشت، غذاها و رستوران‌های رو توصیف می‌کنه؟\n",
        "\n",
        "    یادداشت:\n",
        "    {journal}\"\"\"\n",
        "\n",
        "    # Use LLM to determine if the journal entry is useful\n",
        "    print(f\"{file} -> {print_llm_response(prompt)}\")"
      ],
      "metadata": {
        "id": "1LzzkNzekYdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = [\"cape_town.txt\", \"madrid.txt\", \"rio_de_janeiro.txt\", \"sydney.txt\", \"tokyo.txt\"]\n",
        "\n",
        "for file in files:\n",
        "    f = open(file, \"r\")\n",
        "    journal = f.read()\n",
        "    f.close()\n",
        "\n",
        "    prompt = f\"\"\"متن زیر درباره غذا یا رستوران است. فقط یکی از این دسته‌ها را برای غذاهای ذکرشده انتخاب کن و بنویس:\n",
        "\n",
        "1. گوشت قرمز (گاو، گوسفند، بره و غیره)\n",
        "2. گوشت مرغ یا ماکیان (مرغ، بوقلمون، اردک و غیره)\n",
        "3. غذاهای دریایی یا ماهی (ماهی، میگو، صدف و غیره)\n",
        "4. فاقد گوشت (گیاهی یا وگان)\n",
        "\n",
        "مثال:\n",
        "\"در این رستوران استیک گوساله سرو می‌شود.\" → گوشت قرمز\n",
        "\"خوراک مرغ سوخاری امتحان کردم.\" → گوشت مرغ یا ماکیان\n",
        "\"ماهی سالمون کبابی واقعاً خوشمزه بود.\" → غذاهای دریایی یا ماهی\n",
        "\"سالاد سبزیجات و سوپ عدس خوردم.\" → فاقد گوشت\n",
        "\n",
        "متن:\n",
        "{journal}\n",
        "غذای اصلی این متن به کدام دسته مربوط است؟ فقط نام دسته را به فارسی و بدون توضیح اضافه بنویس.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    print(f\"{file} -> {print_llm_response(prompt)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72tNw4KrgBQO",
        "outputId": "415bd4ed-da94-486f-9f71-571641d515c7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cape_town.txt -> غذاهای دریایی یا ماهی\n",
            "\n",
            "madrid.txt -> فاقد گوشت\n",
            "\n",
            "rio_de_janeiro.txt -> گوشت قرمز\n",
            "\n",
            "sydney.txt -> غذاهای دریایی یا ماهی\n",
            "\n",
            "tokyo.txt -> غذاهای دریایی یا ماهی\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}